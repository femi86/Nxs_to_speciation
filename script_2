#%%
# -*- coding: utf-8 -*-
"""
Created on Wed Mar 06 10:30:50 2019

@author: marafatto_f
"""
'''
Procedure / algortithm / rationale

This script's purpose is to read the rois in a set of maps (based on energy)

inputs:
dir in = dir_out_root of previous script. the rationale is that each sample
folder has subfolders for each energy with each energy having subfolders for the
full spectrum and for the rois. data is saved as tiffs in each. the full spectrum
tiffs can be read by PyMCA easily.
elements allignment = find the element in the filename
references = read in the references and normalize them (athena normalized files)
files to bundle = same filename + energies. optionally, give the energy list
dirs out = LCF, allignment, masks


requirements:
    - make variable with sample names (read dir) --> outside loop
    - make variable with energy names (read subdirs) --> inside each loop, loop through the energies
    - put references in the main folder path as normalized athena files (individual),
      save them with a short filename that has the name in max 9 characters.


operations to do:
        - read all images in a 3/4D array (energies, roi maps) --> pillow or numpy or skimage (read image stack?)
        - make 2D list with energies read in, roi names/filenames
        - allignment --> find index of image to allign in list, apply allignment to all, save in folder allignment

        - make cutoff masks on 15 keV map (mask_cut):
            - histogram (np.histogram) Tl background vs concretions --> evaluate counts and mask (all below value are 0)
            - histogram (np.histogram) Mn counts background --> histogram, set value for bg, select only values that are 5-10 times bg

        - make masks based on cutoff (mask):
            - apply cutoff mask
            - divide Tl/Mn image (15 keV)
            - np.histogram, select ranges (maskN)
        - LCF_all of all images
        - LCF_mask of masked regions:
            - option 1: LCF of all, multiply by maskN, average all values
            - option 2: raw images loop multiply by maskN (increase dimension array by N), average values within masks, LCF
        - fromLCF_mask:
            - save/plot XANES obtained, save XANES reference only values

the principle of this script is to read into dictionaries all the files, this makes it
easier to deal with the data and keeps a track of the data along the whole script.
also, it does not require initialization of the variables, which can provide useful.
However, it may require some thoughts of how to access the actual data when dictionaries
are nested within eachother. Also, there is quite a use of list comprehensions, that
make the code shorter but may be more cryptic to understand.

Notes for future edits:

LCF algorithm is now a non negative least squares method, but in the results
we get ratios that are beyond 1. We should be able to constrain the ratios from 0 to 1.
may be due to normalization?

Also, the normalization may not be optimal now.

'''
import os, glob, sys
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from skimage.io import imread
from skimage.registration import phase_cross_correlation 
import scipy as sp
import pandas as pd
import seaborn as sns
import cv2 # this one needs to be manually installed, get the latest opencv distribution and follow the instructions there

'''
user input
'''
# DIRECTORIES (values):
path = r'E:\Dropbox\Post-doc\data\Diamond_sept17\LCF_out_2019'
run_all = 1 # select 1 to run all or 0 to only run one, specify in list below
run = ['PI_38_w1_ar1'] # name which map should be run, if run_all = 0
refs_ox = r'E:\\Dropbox\\Post-doc\\data\\Diamond_jul18\\refs\\Tl_III'
refs_red = r'E:\\Dropbox\\Post-doc\\data\\Diamond_jul18\\refs\\Tl_I'
ignore = ['ignore','Tl_Mn_3_hole_eV_map2','Tl_Mn_3_hole_eV_map1'] # folders in the input dir to ignore

#PROCESSING:
ROI_opt = 0 # 1 if you want to run on rois, 0 if you want to run the full map as one single roi. will contain also pixel-wise LCF
sel_roi = 0 # 1 if you want to select new rois, 0 if you want to use ones that were predefined before
roi_lcf = 1 # 0 if you just want to just do the averages of the rois, 1 if you want to get the images of the rois with lcf pixel by pixel
grid = 1 # 1 if you want to read the grid values, 0 if none are available
image_scl = 1 # currently not working
moving_avg = 1 # if to make a moving average on the data or not
movavg_shape = 0 # shape of the moving average, 1 for gaussian blur or 0 for normal blur
mov_bin = 3 # the bin for the moving average

mask = 1 # select if you want to mask the numerator 
opt = 1 # edge step filter option
edge_ratio = 3 # edge step threshold to accept (x times the edge step)
Tl_masking = 0 # 1 if you want to mask based on TL, 0 if not
Tl_threshold = 220 # the value for the hi energy, attenuation corrected Tl map for which the Tl(I) background is eliminated


#RATIO (values):
prefix = 'sort_'
alg_el = prefix+'Fe-Ka'
mask_num = prefix+'Tl-La'
mask_num_15 = prefix+'Tl-Lb' # if 15 keV, the element to use is the Lb of Tl since it does not overlap with As
mask_den = prefix+'Mn-Ka'
third_element = prefix+'As-Ka'
master_energy = 1 # select 1 to use the highest energy for the ratio, 0 to use the pymca 15 keV map, 2 to use the 15 keV roi map and Tl-Lb (will add 15kev_roi)
energy_ch = '_pymca','_hiEn','_15kevRoi' # the naming scheme that is used for the data as a function of the master energy parameter chosen
out_chem = '15000' # energy not part of chemical imaging
den_cts_fact = 3 # a factor for the threshold of the denominator ??
num_cts_fact = 3 # a factor for the threshold of the numerator ??
min_hist_cts = 3 # minimum number of histogram counts for the mask to exist
bins_ratio = 30 # how many bins to divide the num/den ratio into for the masks
hist_den_bins = 256 # how many bins to divide the denominator into, to select concretions
bg_bins = 3 # how many bins for the background masks

#ATTENUATION (values): multiply by tx, divide by attenuation, this is when not using 15 kev map. must be in same order as els_to_use variable
atten_on = 0 # 1 if you want to correct attenuation, 0 if only raw values
num_scal = 0.005 # if no attenuation, enter the value you want to scale the numerator if there is an external calibration for example
els_to_use = [mask_num,mask_den,third_element]
atten = pd.Series([0.4061,0.0016,0.0033,204.39*165.033,54.95*77.955,74.92*148.610],
             index=['tx_Tl','tx_Mn','tx_As','att_mass_Tl','att_mass_Mn','att_mass_As'])#g/mol * cm2/g

#OTHER TOOLS
variant_comparison = 0 # in order to compare different datasets, the masks need to be identical to the first map

'''
function definition
'''
def atten(master_energy,atten_on):
    if master_energy == 1:
        att_Tl = atten.tx_Tl * atten.att_mass_Tl
        att_Mn = atten.tx_Mn * atten.att_mass_Mn
        att_As = atten.tx_As * atten.att_mass_As
    else:
        if master_energy == 2:
            mask_num = mask_num_15
            els_to_use[1] = 'sort_Tl-Lb'
            # tot_att = att_mass
        att_Tl = atten.att_mass_Tl
        att_Mn = atten.att_mass_Mn
        att_As = atten.att_mass_As
    return att_Tl, att_Mn, att_As

def safe_mkdir(file_path,a = False):
    if not os.path.exists(file_path):
        os.makedirs(file_path)
    if a:
        return file_path

def find_nearest(a, a0):
    "Element in nd array `a` closest to the scalar value `a0`"
    idx = np.abs(a - a0).argmin()
    return a.flat[idx]

def progbar(text,curr, total, full_progbar):
    frac = curr/total
    filled_progbar = round(frac*full_progbar)
    #print('\r','\t '+'#'*filled_progbar + '-'*(full_progbar-filled_progbar), '{:>7.2%}'.format(frac), end='')
    text = '\t'+text+': '+'#'*filled_progbar + '-'*(full_progbar-filled_progbar)+ '{:>7.2%}'.format(frac)
    sys.stdout.write('\r'+text)
    sys.stdout.flush()

def mov_avg(array):
    if movavg_shape == 1:
        result = cv2.GaussianBlur(array,(mov_bin,mov_bin),0)
    elif movavg_shape == 0:
        result = cv2.blur(array,(mov_bin,mov_bin))
    return result

def RGB_fun(arR,arG,arB):
    R = np.array(np.around(arR/np.nanmax(arR)*256),np.uint8)
    G = np.array(np.around(arG/np.nanmax(arG)*256),np.uint8)
    B = np.array(np.around(arB/np.nanmax(arB)*256),np.uint8)
    RGB = cv2.merge((B,G,R))
    return RGB

def ROIs(sel_roi,el_norm, num, den, directory,scl): 
    '''
    this function reads in alligned images from a chemical map, allows the user to
    select a series of rois, then saves each selected roi in individual objects
    for further independent processing.
    '''
    font = cv2.FONT_HERSHEY_SIMPLEX
    ROI = {} # first roi is the fullmap
    roi_coord = {}
    roi_masks = {}
    loop = True
    count = 1
    Tl = num
    empty = np.zeros(np.shape(Tl))
    canv_incr = 3
    def inc_canv(array): # this is set for rgb images, so considers a 3d array where 3rd dimension is RGB
        row = np.zeros((canv_incr,np.shape(array)[1],3),np.uint8)
        col = np.zeros((np.shape(array)[0]+canv_incr*2,canv_incr,3),np.uint8)
        return np.hstack((col,np.vstack((row,array,row)),col))
    Mn = den
    image1 = RGB_fun(Tl/np.nanmax(Tl)*1.1,Mn/np.nanmax(Mn)*1.1, empty)
    image2 = RGB_fun(Tl*1.1,Mn*1.1,empty)
    image3 = RGB_fun(Tl,Mn,empty)
    try:
        image4 = cv2.imread(os.path.join(dirname,'fullmap','LCF', 'fullmap_redR_nanG_oxB_TlIntScale.tif'))
    except:
        print('fullmap not available, check the directory, or run full lcf first')
        image4 = RGB_fun(empty,empty,empty)    
    outimage1 = inc_canv(image1)
    outimage2 = inc_canv(image2)
    imSh = outimage2.shape
    outimage2 = cv2.resize(outimage2,(int(imSh[0])*scl,int(imSh[0])*scl))
    outimage3 = inc_canv(RGB_fun(empty,empty,empty))
    images = [outimage1,outimage2,outimage3]
    image_names = ['ROIs_RTl_GMn_debug.tif','ROIs_TlMnRatio.tif','only_areas.tif']
    if not sel_roi:
        try:
            roi_coord = pd.read_csv(os.path.join(directory,'roi_coordinates.csv'))
        except:
            raise  ValueError('no such file as roi_coordinates.csv in the output folder')
            print(ValueError)
        for r in range(roi_coord.shape[0]):
            X1,Y1,width,height = int(roi_coord['X1'][r]),int(roi_coord['Y1'][r]),int(roi_coord['width'][r]),int(roi_coord['height'][r])
            ROI['roi_n'+str(r+1)] = el_norm[:,Y1:Y1+height, X1:X1+width]
            roi_masks['roi_n'+str(r+1)] = [Y1,Y1+height,X1,X1+width]
            X1_shift, Y1_shift = X1+canv_incr, Y1+canv_incr
            center = (X1_shift,Y1_shift-2)
            for image in images:
                cv2.rectangle(image,(X1_shift,Y1_shift),(X1_shift+width,Y1_shift+height),(255,0,0),2)
                cv2.putText(image,'ROI'+str(r+1),center,font,0.5,(255,0,0),1) 
        [cv2.imwrite(os.path.join(directory,samp_name+img_n),image) for image in images for img_n in image_names]

    #%%
    elif sel_roi:
        try:
            os.rename(os.path.join(directory,'roi_coordinates.csv'),
                      os.path.join(directory,'roi_coordinates.csv.bkup'))
        except:
            print('there was no previous coordinates file to backup')
        while loop:
            roi_ID = 'ROI{}'.format(str(count))
            cv2.imshow('Tl red vs Mn blue map',outimage2)
            print('select on Tl vs Mn image Roi n.{}, type "c" to cancel selection,',
                  'then hit \n enter twice to continue, or \n enter + q to stop'
                  .format(roi_ID))
            r = cv2.selectROI('Tl red, Mn green, scaled by Tl and Mn and contrast',image1,False) # the image here should be the Tl/Mn ratio, with also a plot of Tl max intensity?
            r1 = (int(r[0]/scl),int(r[1]/scl),int(r[2]/scl),int(r[3]/scl))
            roi_coord['roi'+str(count)] = [r1[0],r1[1],r1[2],r1[3]]
            k = cv2.waitKey(0) # this is to read the quit signal
            if k == ord('q'):
                loop=False
                for n,image in enumerate(images):
                    cv2.imwrite(os.path.join(directory,samp_name+image_names[n]),image)
                print('ok, exiting roi selection')
            else:
                ROI['roi_n'+str(count)] = el_norm[:,r1[1]:r1[1]+r1[3], r1[0]:r1[0]+r1[2]]
                roi_masks['roi_n'+str(count)] = [r1[1],r1[1]+r1[3],r1[0],r1[0]+r1[2]]
                X1_shift, Y1_shift = r1[0]+canv_incr, r1[1]+canv_incr
                center = (X1_shift,Y1_shift-1)
                for image in images:
                    cv2.rectangle(image,(X1_shift,Y1_shift),(X1_shift+r1[2],Y1_shift+r1[3]),(255,0,0),2)
                    cv2.putText(image,roi_ID,center,font,0.5,(255,0,0),1)
                count +=1
            cv2.destroyWindow('Tl red vs Mn blue map')
            cv2.destroyWindow('Tl red, Mn green, scaled by Tl and Mn and contrast') 
        tmp = pd.DataFrame.from_dict(data=roi_coord,orient='index',columns=['X1','Y1','width','height'])
        tmp.to_csv(os.path.join(directory,'roi_coordinates.csv'))
    return ROI, roi_masks, roi_coord

def pixelLCF(shape,el_norm,nor_vals,ref_list):
    LCF_1comp = np.zeros((shape[0],shape[1]))
    LCF_1comp_val = np.zeros((2,shape[0],shape[1]))
    LCF_1comp_res = np.zeros((shape[0],shape[1]))
    for x in range(shape[0]):
        for y in range(shape[1]):
            LCF_res, LCF_val = np.empty(len(ref_list)),np.empty((len(ref_list),2))
            for ref in range(len(ref_list)):
                fit_mat = np.vstack((nor_vals[:,ref],np.zeros(nor_vals[:,ref].shape))).transpose() # we add a variable that is all ones to make it work, not sure if it does something bad or not...
                tmp_1 = sp.optimize.lsq_linear(fit_mat,el_norm[:,x,y],(0,1)) # for the moment does not work with the general lsq_linear
                LCF_res[ref] = np.sum(np.array([x1**2 for x1 in tmp_1['fun']]))
                LCF_val[ref,:] = np.array([x2 for x2 in tmp_1['x']])
            try:
                lowest = np.amin(np.ma.masked_equal(LCF_res,0))
                index = np.where(LCF_res == lowest)[0][0]
                LCF_1comp[x,y] = index+1 # need to mask the zero values because we are working with masked values, otherwise it will select the first ref always
                LCF_1comp_val[:,x,y] = LCF_val[index]
                LCF_1comp_res[x,y] = LCF_res[index]
            except:
                LCF_1comp[x,y] = 0
                LCF_1comp_val[:,x,y] = 0
        progbar('pixelLCF',x,shape[0]-1,20)
    return LCF_1comp, LCF_1comp_res, LCF_1comp_val

def pixel_2compLCF(shape,el_norm,nor_vals,couples):
    LCF_2comp = np.zeros((2,shape[0],shape[1]))
    LCF_2comp_val = np.zeros((2,shape[0],shape[1]))
    LCF_2comp_res = np.zeros((shape[0],shape[1]))
    for x in range(shape[0]):
        for y in range(shape[1]):
            LCF_res_2, LCF_val_2 = np.empty(len(couples)), np.empty((len(couples),2))
            for cpind,couple in enumerate(couples): # the couples are such that the first is the reduced, the second the oxidized
                tmp_2 = sp.optimize.lsq_linear(nor_vals[:,couple],el_norm[:,x,y],(0,1))
                LCF_val_2[cpind,:] = np.array([x2 for x2 in tmp_2['x']])
                LCF_res_2[cpind] = np.sum(np.array([x1**2 for x1 in tmp_2['fun']]))
            try:
                lowest2 = np.amin(np.ma.masked_equal(LCF_res_2,0))
                index2 = np.where(LCF_res_2 == lowest2)[0][0]
                LCF_2comp[:,x,y] = [x3+1 for x3 in couples[index2]]
                LCF_2comp_val[:,x,y] = LCF_val_2[index2]
                LCF_2comp_res[x,y] = LCF_res_2[index2]
            except:
                LCF_2comp[:,x,y] = 0
                LCF_2comp_val[:,x,y] = 0
                LCF_2comp_res[x,y] = 0
        progbar('2comp_lcf',x,shape[0]-1,20)
    return LCF_2comp, LCF_2comp_res, LCF_2comp_val

def LCF_sel(shape,len_red,LCF_2comp, LCF_2comp_val,LCF_2comp_res,LCF_1comp, LCF_1comp_res):
    LCF_select = np.full((2,shape[0],shape[1]),np.nan)
    LCF_sel_oxstate = np.full((2,shape[0],shape[1]),np.nan)
    for x in range(shape[0]):
        for y in range(shape[1]):
            if LCF_2comp_res[x,y] <= 0.8*LCF_1comp_res[x,y]:
                LCF_select[:,x,y] = LCF_2comp[:,x,y]
                LCF_sel_oxstate[:,x,y] = LCF_2comp_val[:,x,y]/np.sum(LCF_2comp_val[:,x,y]) # this will populate with the values of the components, scaled to 1
            else:
                if LCF_1comp[x,y] < len_red:
                    LCF_select[0,x,y] = LCF_1comp[x,y]
                    LCF_sel_oxstate[0,x,y] = 1
                else:
                    LCF_select[1,x,y] = LCF_1comp[x,y]
                    LCF_sel_oxstate[1,x,y] = 1
    return LCF_select, LCF_sel_oxstate

''' 
code
'''

## reading part
print('###########')
print("LET'S GO!!!")
print('###########')
    
refs_red_ls = glob.glob(os.path.join(refs_red,'*.nor'))
refs_ox_ls = glob.glob(os.path.join(refs_ox,'*.nor'))
redox = ['red','ox']
ref_list = refs_red_ls+refs_ox_ls
red_ls = range(0,len(refs_red_ls))
ox_ls = range(len(refs_red_ls),len(ref_list))
couples = [(red,ox) for red in red_ls for ox in ox_ls]
len_red = len(refs_red_ls)

samples = [os.path.join(path,y) for y in [x[1] for x in os.walk(path)][0]] # read all the samples in all subdirectories
if not run_all:
    samples = [sample for sample in samples if os.path.basename(sample) in run]
dir_out_root = ['masks','LCF']
dir_out_r = os.path.join(path,'LCF_out')
to_remove = [dir_out_r] + [os.path.join(path,ig) for ig in ignore]
samples = [sample for sample in samples if sample not in to_remove]

if atten_on:
    att_Tl, att_Mn, att_As = atten(master_energy,atten_on)
else:
    att_Tl, att_Mn, att_As = 1/num_scal,1,1
#attenuations = att_Tl, att_Mn, att_As
#%%
samp_count = 0
for sample in samples:
#%%
    samp_name = os.path.basename(sample)+energy_ch[master_energy]
    print('#*#*#*#*#*#*#*#*#*#*#*#*#')
    print('running sample {}'.format(samp_name))
    energies = [os.path.join(sample,y) for y in [x[1] for x in os.walk(sample)][0]]
    LCF_energies = [energy for energy in energies if out_chem not in energy]
    en_values = [float(os.path.basename(energy)) for energy in LCF_energies]
    array, allign = {}, {}
    array = {key:{} for key in energies} # this needs to be the 4D shape of the data. so energies x rois x mapsize
    allign = {key:{} for key in energies}
    '''
    this part below is to figure out if and where there is a different sized map in the set.
    the idea is to upsize the small maps to the big one to not loose info of the big ones
    '''
    if grid:
        grid = [[np.loadtxt(text) for text in glob.glob(os.path.join(energy,'*.txt'))] for energy in energies]
        grid_shape = [grid[energy][0].shape for energy in range(len(grid))]
        grid_dict = {os.path.basename(energy)+'eV':grid_shape[en] for en,energy in enumerate(energies)}
        gridindex = dict((i, grid_shape.count(i)) for i in grid_shape)
        if len(gridindex) > 1:
            print("there is one map that has a different size. I'll interpolate it to the other maps' size (increase)")
            print('')
            grid_min_ind = grid_shape.index(min(gridindex))
            grid_max_ind = grid_shape.index(max(gridindex))
            tmp = pd.DataFrame(data=grid_dict,index=['X','Y']).transpose()
            tmp.to_csv(os.path.join(sample,'diagnostic_interpolation.txt'),sep='\t')
        else:
            grid_min_ind, grid_max_ind = -1,-1
#this part below loops over the different energies
    alg_el_sel = []
    count = 0 # this is to initialize the overall_mismatch variable
    for nen,energy in enumerate(energies): # this will iterate over all energies within a sample.
        tmp = glob.glob(os.path.join(energy,'rois','*.tif'))
        if moving_avg:
            sfx = 'mv_avg{}x{}'.format(str(mov_bin),str(mov_bin))
            filenames = [os.path.basename(y)[:os.path.basename(y).find('.')]+sfx for y in tmp]
        else:
            filenames = [os.path.basename(y)[:os.path.basename(y).find('.')] for y in tmp]
        alg_el_sel.append([filename for filename in filenames if alg_el in filename][0])
        if grid:
            if nen == grid_min_ind:
                X,Y = (grid[grid_max_ind][0],grid[grid_max_ind][1])
                for y,x in enumerate(tmp):
                    array[energy][filenames[y]] = cv2.resize(imread(x),(len(X),len(Y)))
                allign[energy] = {alg_el_sel[nen]:array[energy][alg_el_sel[nen]]}
            else:
                array[energy] = {filenames[y]:imread(x) for y,x in enumerate(tmp)}
                allign[energy] = {alg_el_sel[nen]:array[energy][alg_el_sel[nen]]}
        else:
            array[energy] = {filenames[y]:imread(x) for y,x in enumerate(tmp)}
            allign[energy] = {alg_el_sel[nen]:array[energy][alg_el_sel[nen]]}
        if count == 0:
            overall_mismatch = np.empty(allign[energies[0]][alg_el_sel[0]].shape)
## 
        '''
        allignment part
        this algorithm here makes the allignment but requires the files to all have the same shape.
        maybe there could be some other algorithm that can also allign if the images are different
        since there should be no rotation, it only fixes translation in X and Y. there should actually
        only be changes in the Y direction, but there is also probably changes in the beam spot profile
        which we make the assumption are negligeable (sub-pixel)
        '''
        shift, error, diffphase = phase_cross_correlation(allign[energies[0]][alg_el_sel[0]], allign[energy][alg_el_sel[nen]],upsample_factor=100)
        diagnostic = sp.ndimage.shift(allign[energy][alg_el_sel[nen]],shift) - allign[energies[0]][alg_el_sel[0]]
        try:
            overall_mismatch = overall_mismatch + np.abs(diagnostic)
        except:
            if allign[energies[nen]][alg_el_sel[0]].shape != allign[energies[0]][alg_el_sel[0]].shape:
                print('the images are not the same size')
                print('')
        for key in array[energy]:
            # this algorithm below makes the shift based on the calculated translation.
            array[energy][key] = sp.ndimage.shift(array[energy][key],shift)
            if moving_avg:
                array[energy][key] = mov_avg(array[energy][key])
                dirname =  samp_name+'_out_movavg_{}x{}'.format(str(mov_bin),str(mov_bin))
            else:
                dirname = samp_name +'_out'
            out_all = os.path.join(dir_out_r,dirname,'allign',os.path.basename(energy))
            safe_mkdir(out_all)
            img1 = Image.fromarray(array[energy][key])
            img_name = os.path.join(out_all,key+'_alligned.tif') # check if it actually works here
            img1.save(img_name)
        count += 1
    dirname = os.path.join(dir_out_r,dirname)
    dir_out = [os.path.join(dirname,direc) for direc in dir_out_root]
    for direc in dir_out:
        safe_mkdir(direc)
    diag = Image.fromarray(overall_mismatch)
    diag_name = os.path.join(os.path.dirname(out_all),'%s_allign_diag.tif' % alg_el)
    diag.save(diag_name)
    shape = np.shape(overall_mismatch)
# reference reading
    print('\t######################')
    print('\t# reading references #')
    print('\t######################')

    ref_head = [os.path.basename(ref)[0:10] for ref in ref_list]
    N_ref = len(ref_list)
    nor_vals = np.zeros((len(LCF_energies),len(ref_list)))
    energy_refs = [float(os.path.basename(energy)) for energy in LCF_energies]
    for index,reference in enumerate(ref_list):
        ref = np.loadtxt(reference)
        for en,energy in enumerate(energy_refs):
            value = ref[np.where(np.around(ref[:,0],decimals=0)==energy),1]
            nearest = ref[np.abs(ref[:,0]-energy).argmin(),1]
            if value.size == 1:
                nor_vals[en,index] = value.item()
            elif value.size == 0:
                nor_vals[en,index] = nearest
            else:
                nor_vals[en,index] = np.mean(value)
    nor_vals = nor_vals/nor_vals[-1] # this is make the refs similar to the data (last energy is 1 in the data)--> "normalizing" the references also in case they were not already
# correcting the attenuation, currently not working correctly, probably due to As being taken from LCF energies
    
#    for energy in array:
#        for ind,el in enumerate(els_to_use):
#            for key in array[energy]:
#                if el in array[energy][key]:
#                    array[energy][key] = array[energy][key]*attenuations[ind]
    
    
    '''
    normalization part -- CAN STILL BE IMPROVED MAYBE?
    this part is to attempt to make a normalization of the maps. it will take the average for
    the highest energy map, and the minimum for the lowest energy map to normalize the data.
    this may be not the best solution, but I did not find something better for the moment
    '''
    # here below divide by the attenuation of Tl by the filter
    hi_El = array[LCF_energies[-1]][[k for k in array[LCF_energies[-1]] if mask_num in k][0]]/att_Tl
    lo_El = array[LCF_energies[0]][[k for k in array[LCF_energies[0]] if mask_num in k][0]]/att_Tl
    As_map = array[LCF_energies[-1]][[k for k in array[LCF_energies[-1]] if third_element in k][0]]/att_As # takes highest energy map
    Tl_map = array[LCF_energies[-1]][[k for k in array[LCF_energies[-1]] if mask_num in k][0]]/att_Tl
    Mn_map = array[LCF_energies[-1]][[k for k in array[LCF_energies[-1]] if mask_den in k][0]]/att_Mn
    
    correct_vals = [As_map,Tl_map,Mn_map]
    names = ['As_atten','Tl_atten','Mn_atten']
    dir_atten = safe_mkdir(os.path.join(dirname,'attenuation_corrected'),1)
    for ind_att,mp in enumerate(correct_vals):
        Image.fromarray(mp).save(os.path.join(dir_atten,names[ind_att]+'.tif'))
    if Tl_masking:
        Tl_mask = np.copy(Tl_map)
        Tl_mask[Tl_mask<=Tl_threshold] = 0
        Tl_mask[Tl_mask>Tl_threshold] = 1
    else:
        Tl_mask = np.ones(np.shape(Tl_map))
    
    if master_energy:
        sel_en = LCF_energies[-1]
    else:
        try: # selection of the correct ROI (Tl and Mn) at the right energy from the dictionaries
            sel_en = [en for en in energies if out_chem in en][0]
        except:
            print('there is no datafile for the mask energy (i.e. high energy overview map), using highest energy available')
            print('')
            sel_en = LCF_energies[-1]
    El_sel = [k for k in array[sel_en] if mask_num in k][0]
    Den_sel = [k for k in array[sel_en] if mask_den in k][0]
    Den_raw = np.ma.masked_less(array[sel_en][Den_sel]*Tl_mask,1)/att_Mn
    El_raw = np.ma.masked_less(array[sel_en][El_sel]*Tl_mask,1)/att_Tl
    hi_El_msk = np.ma.masked_array(hi_El,Den_raw.mask)
    lo_El_msk = np.ma.masked_array(lo_El,Den_raw.mask)
    Tl_int_scal = np.ma.fix_invalid(hi_El/np.nanmax(hi_El),fill_value=0)
    Mn_int_scal = np.ma.fix_invalid(Den_raw/np.nanmax(Den_raw),fill_value=0)
# mask for all data
    '''
    here is a mask to select only the pixels with minimum counts higher than background for Tl
    it takes the mean value of the highest energy map and uses this as a threshold for creating a num_mask
    '''
    if mask:
        if opt:
            mask_Num = np.greater_equal(hi_El,lo_El*edge_ratio)
        else:
            mask_Num = np.greater_equal(hi_El,np.mean(lo_El))
        Image.fromarray(mask_Num.astype(int)).save(os.path.join(dir_out[1],'num_mask.tif'))
    else:
        mask_Num = np.ones(np.shape(hi_El))

# population of the arrays with normalized data, fixed for attenuation of filter
    el_norm = np.zeros((len(LCF_energies),shape[0],shape[1]))
    for Eind, energy in enumerate(LCF_energies):
        sel_El = [k for k in array[energy] if mask_num in k][0]
        data = (((array[energy][sel_El]*Tl_mask)/att_Tl-lo_El)/(hi_El-lo_El))*mask_Num # used to be att
        el_norm[Eind,:,:] = np.ma.fix_invalid(data,fill_value=0)

    ''' 
    LCF selection/rating based on residuals after testing all references on each pixel
    1. evaluate the residuals for all references for each pixel
    2. for each pixel, select only the value with lowest residual and assign it in the map
    3. save a list with the reference and the index
    4. evaluate the 2 component fit that works the best, with the lowest residual
    5. select in a final map whether the 1 component is better or the 2 component
    '''

# ROI selection
    if ROI_opt:
        ROI, roi_masks, roi_coord = ROIs(sel_roi,el_norm, hi_El, Den_raw, dirname,image_scl)
        outfilename = 'roi.csv'
    else:
        ROI, roi_masks = {},{}
        ROI['fullmap'] = el_norm
        roi_masks['fullmap'] = [0,np.shape(el_norm)[1], 0, np.shape(el_norm)[2]]
        outfilename = 'full.csv'

    
        print('\n\t# saving LCF images #')
        print('\t#################')

#%%    
    valid_roi = [roi for roi in ROI if ROI[roi].size] #  this is because the quit does not always work
    LCF_dict= {}
    LCF_avg = {}
    allpix = {}
    spectrum = {}
    
    for roi_ind,roi in enumerate(valid_roi):      
        print('\t')
        print('\t# running roi {} of {} #'.format(roi_ind,len(valid_roi)+1))
        print('\t#################')
        dir_out = [os.path.join(dirname,roi,xpath) for xpath in dir_out_root]  
        [safe_mkdir(dir_tmp) for dir_tmp in dir_out]
        x1,x2,y1,y2 = roi_masks[roi]
        
        hi_el_roi = hi_El[x1:x2,y1:y2]
        Den_raw_roi = Den_raw[x1:x2,y1:y2]
        El_raw_roi = El_raw[x1:x2,y1:y2]
        mask_num_roi = mask_Num[x1:x2,y1:y2]
        Tl_mask_roi = Tl_mask[x1:x2,y1:y2]
        As_roi = As_map[x1:x2,y1:y2]
        Tl_roi = Tl_map[x1:x2,y1:y2]
        Mn_roi = Mn_map[x1:x2,y1:y2]
        Tl_int_scal_roi = Tl_int_scal[x1:x2,y1:y2]
        Mn_int_scal_roi = Mn_int_scal[x1:x2,y1:y2]
        # this part saves all the pixel results as images
        shape_roi = (x2-x1,y2-y1)    
        G = np.zeros((shape_roi[0],shape_roi[1]))
        allpix[roi] = pd.DataFrame({'Tl_roi':np.ma.masked_less_equal(Tl_roi*Tl_mask_roi,0).flatten(),
                  'Mn_roi':np.ma.masked_less_equal(Mn_roi*Tl_mask_roi,0).flatten(), 
                  'TlMn_ratio_roi':np.ma.masked_less_equal(Tl_roi*Tl_mask_roi,0).flatten()/np.ma.masked_less_equal(Mn_roi*Tl_mask_roi,1).flatten(),
                  'As_roi':np.ma.masked_less_equal(As_roi*Tl_mask_roi,0).flatten()})
        roi_el_norm = el_norm[:,x1:x2, y1:y2]
        roi_spectrum = np.mean(roi_el_norm.reshape(len(LCF_energies), -1), 1)
        spectrum[roi] = pd.Series(roi_spectrum, index=en_values)
        

        if roi_lcf:
            print('\n\t# running pixel LCF on ROI %s #' %roi)
            print('\t#################')
                  

            shape_roi = (x2-x1,y2-y1) # this could be 1 less than what it should be
            LCF_sel_header = ['2comp_red','2comp_ox','1comp']

            print('\n\t# saving ROI %s images #' %roi)
            print('\t#################')
            
            LCF_1comp, LCF_1comp_res, LCF_1comp_val = pixelLCF(shape_roi,ROI[roi],nor_vals,ref_list)
            LCF_2comp, LCF_2comp_res, LCF_2comp_val = pixel_2compLCF(shape_roi,ROI[roi],nor_vals,couples)
            LCF_select, LCF_sel_oxstate = LCF_sel(shape_roi,len_red,LCF_2comp, LCF_2comp_val,LCF_2comp_res,LCF_1comp, LCF_1comp_res)
            
            RGB = RGB_fun(LCF_sel_oxstate[0],G,LCF_sel_oxstate[1])
            cv2.imwrite(os.path.join(dir_out[1], roi+'_redR_nanG_oxB_nssr_sel.tif'),RGB)
            
            RGB = RGB_fun(LCF_2comp_val[0],G,LCF_2comp_val[1])
            cv2.imwrite(os.path.join(dir_out[1], roi+'_redR_nanG_oxB_abs.tif'),RGB)
            
            RGB_scTl = RGB_fun(LCF_sel_oxstate[0]*Tl_int_scal_roi,G,LCF_sel_oxstate[1]*Tl_int_scal_roi)
            cv2.imwrite(os.path.join(dir_out[1], roi+'_redR_nanG_oxB_TlIntScale.tif'),RGB_scTl)
        
            RGB_scMn = RGB_fun(LCF_sel_oxstate[0]*Mn_int_scal_roi,G,LCF_sel_oxstate[1]*Mn_int_scal_roi)
            cv2.imwrite(os.path.join(dir_out[1], roi+'_redR_nanG_oxB_MnIntScale.tif'),RGB_scMn)
            
            Image.fromarray(LCF_1comp).save(os.path.join(dir_out[1], roi+'1comp_rating.tif' ))
            Image.fromarray(LCF_1comp_res).save(os.path.join(dir_out[1], roi+'1comp_NSSR.tif' ))
            
            for couple in range(2):
                Image.fromarray(LCF_2comp[couple]).save(os.path.join(dir_out[1], roi+'_%s_rating.tif' % redox[couple]))
            Image.fromarray(LCF_2comp_res).save(os.path.join(dir_out[1], roi+'_NSSR.tif'))
            for num,comp in enumerate(LCF_2comp_val):
                Image.fromarray(LCF_2comp_val[num]).save(os.path.join(dir_out[1], roi+'_2comp_%s_val.tif' % redox[num]))
                Image.fromarray(LCF_sel_oxstate[num]).save(os.path.join(dir_out[1], roi+'_2comp_norm%s_val.tif' % redox[num]))

            for ind, index in enumerate(LCF_select):
                Image.fromarray(index).save(os.path.join(dir_out[1], roi+'LCF_sel_%s_rating.tif' % LCF_sel_header[ind]))
            refs_corr = ['no LCF']+ref_head
            refs = pd.DataFrame([[refs_corr[b] for b in a] for a in LCF_2comp.reshape(2,-1).T.astype(int)],
                                columns=['LCF_ref_ox','LCF_ref_red'])
            allpix[roi]['Tl_III']=np.ma.masked_invalid(LCF_sel_oxstate[1]).flatten()
            allpix[roi] = allpix[roi].join(refs)

            # make the correlations of Tl and Mn with oxidation state
            cleaned = allpix[roi].dropna()
            plt.rcParams.update({'font.size':18})
            points = plt.scatter(cleaned['Mn_roi'],cleaned['Tl_roi'],c=cleaned['Tl_III'],vmin = 0, vmax = 1,s=10,cmap='Spectral_r')
            m,b = np.polyfit(cleaned.Mn_roi,cleaned.Tl_roi,1)
            cbar = plt.colorbar(points)
            cbar.set_label('Tl(III) percent')
            plt.xlim(cleaned.Mn_roi.min()-10,cleaned.Mn_roi.max()+10)
            plt.ylim(cleaned.Tl_roi.min()-10,cleaned.Tl_roi.max()+10)
            sb_plt = sns.regplot('Mn_roi','Tl_roi',data=cleaned,scatter = False,color='.1',
                                 line_kws={'color':'red','linestyle':'dashed'})
            sb_plt.set(ylabel='Tl raw counts',xlabel='Mn raw counts')
            plt.text(cleaned.Mn_roi.min()-10,cleaned.Tl_roi.max(),
                     'regr. vals\nTl/Mn = {}\nTl background = {}'.format(round(m,3),round(b,3)),alpha=.75)
            plt.savefig(os.path.join(dir_out[1],'{}_Tl_Mn_correlations.svg'.format(roi)))
            plt.close()
            
            
        third_el = [k for k in array[sel_en] if third_element in k][0]
        third_el2 = array[sel_en][third_el]
        RGB_Mn = RGB_fun(Den_raw_roi,G,hi_el_roi)
        cv2.imwrite(os.path.join(dir_out[1], roi+'_MnR_nanG_TlB_scaleint.tif'),RGB_Mn)
        
        RGB_TlInt = RGB_fun(Den_raw_roi*Tl_int_scal_roi,G,hi_el_roi*Tl_int_scal_roi)
        cv2.imwrite(os.path.join(dir_out[1], roi+'_MnR_nanG_TlB_scaleTl.tif'),RGB_TlInt)
        
        RGB_MnInt = RGB_fun(Den_raw_roi*Mn_int_scal_roi,G,hi_el_roi*Mn_int_scal_roi)
        cv2.imwrite(os.path.join(dir_out[1], roi+'_MnR_nanG_TlB_scaleMn.tif'),RGB_MnInt)
#%%        
# save all the text files with elaborated results
    tmp = pd.DataFrame(data={str(index+1):ref for index,ref in enumerate(ref_head)},index = ['reference'])
    tmp = tmp.transpose()

# this is raw if wanting to look at the pseudo xanes
    roi_option = ['fullmap','rois']
    im_lcf = ['no_im_lcf','im_lcf']
    with pd.ExcelWriter(os.path.join(dirname,dir_out_root[1],'output_{}_{}.xlsx'.format(roi_option[ROI_opt],im_lcf[roi_lcf]))) as writer:
        tmp.to_excel(writer,sheet_name='ref_list')
        for roi in valid_roi:
            allpix[roi].to_excel(writer,sheet_name='{}_allpixels'.format(roi))
            spectrum[roi].to_excel(writer,sheet_name='{}_avg_spectrum'.format(roi))
    samp_count +=1
