#%%
# -*- coding: utf-8 -*-
"""
Created on Wed Mar 06 10:30:50 2019

@author: marafatto_f
"""
'''
Procedure / algortithm / rationale

This script's purpose is to read the rois in a set of maps (based on energy)

inputs:
dir in = dir_out_root of previous script. the rationale is that each sample
folder has subfolders for each energy with each energy having subfolders for the
full spectrum and for the rois. data is saved as tiffs in each. the full spectrum
tiffs can be read by PyMCA easily.
elements allignment = find the element in the filename
references = read in the references and normalize them (athena normalized files)
files to bundle = same filename + energies. optionally, give the energy list
dirs out = LCF, allignment, masks


requirements:
    - make variable with sample names (read dir) --> outside loop
    - make variable with energy names (read subdirs) --> inside each loop, loop through the energies
    - put references in the main folder path as normalized athena files (individual),
      save them with a short filename that has the name in max 9 characters.


operations to do:
        - read all images in a 3/4D array (energies, roi maps) --> pillow or numpy or skimage (read image stack?)
        - make 2D list with energies read in, roi names/filenames
        - allignment --> find index of image to allign in list, apply allignment to all, save in folder allignment

        - make cutoff masks on 15 keV map (mask_cut):
            - histogram (np.histogram) El1 background vs concretions --> evaluate counts and mask (all below value are 0)
            - histogram (np.histogram) El2 counts background --> histogram, set value for bg, select only values that are 5-10 times bg

        - make masks based on cutoff (mask):
            - apply cutoff mask
            - divide El1/El2 image (15 keV)
            - np.histogram, select ranges (maskN)
        - LCF_all of all images
        - LCF_mask of masked regions:
            - option 1: LCF of all, multiply by maskN, average all values
            - option 2: raw images loop multiply by maskN (increase dimension array by N), average values within masks, LCF
        - fromLCF_mask:
            - save/plot XANES obtained, save XANES reference only values

the principle of this script is to read into dictionaries all the files, this makes it
easier to deal with the data and keeps a track of the data along the whole script.
also, it does not require initialization of the variables, which can provide useful.
However, it may require some thoughts of how to access the actual data when dictionaries
are nested within eachother. Also, there is quite a use of list comprehensions, that
make the code shorter but may be more cryptic to understand.

Notes for future edits:

LCF algorithm is now a non negative least squares method, but in the results
we get ratios that are beyond 1. We should be able to constrain the ratios from 0 to 1.
may be due to normalization?

Also, the normalization may not be optimal now.



Update 2020 07 30

generalization of the script. the script reads in maps at different energies, 
alligns them based on one element that does not change and has enough features
for the algorithm, and then gives the results in terms of LCF (element 1 at 2 
oxidation states), in terms of element 1 / element 2 ratios, and also with a
third element if needed.

it reads in an hdf5 file that is generated from another script, that reads in 
FDA files


'''
import os, glob, sys
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from skimage.io import imread
from skimage.registration import phase_cross_correlation 
import scipy as sp
import pandas as pd
import seaborn as sns
import cv2 # this one needs to be manually installed, get the latest opencv distribution and follow the instructions there
import marafatto_useful_libs as mul
import h5py
'''
user input
'''
# DIRECTORIES (values):
path: str = r'E:\switchdrive\phoenix_jul20\fda_program\data\2020'
run_all = 1 # select 1 to run all or 0 to only run one, specify in list below
run = [''] # name which map should be run, if run_all = 0
refs_ox: str = r'E:\Dropbox\Post-Doc_II\data\phoenix\2020\refs\ox'
refs_red: str = r'E:\Dropbox\Post-Doc_II\data\phoenix\2020\refs\red'
ignore = [''] # folders in the input dir to ignore

#PROCESSING:
ROI_opt = 0 # 1 if you want to run on rois, 0 if you want to run the full map as one single roi. will contain also pixel-wise LCF
sel_roi = 1 # 1 if you want to select new rois, 0 if you want to use ones that were predefined before
roi_lcf = 1 # 0 if you just want to just do the averages of the rois, 1 if you want to get the images of the rois with lcf pixel by pixel
moving_avg = 0 # if to make a moving average on the data or not
movavg_shape = 0 # shape of the moving average, 1 for gaussian blur or 0 for normal blur
mov_bin = 3 # the bin for the moving average

mask = 0 # select if you want to mask the numerator 
opt = 1 # edge step filter option
edge_ratio = 3 # edge step threshold to accept (x times the edge step)
El1_masking = 0 # 1 if you want to mask based on an element, 0 if not
El1_threshold = 220 # the value for the hi energy, attenuation corrected El map for which the El background is eliminated

#RATIO (values):
alg_el = 'KKa_sum_cps' # element to use for the allignment
El1_name = 'SKa_sum_cps' # element for the numerator
El2_name = 'FeKa_sum_cps' # element to use as the denominator, element 2
El3_name = 'CaKa_sum_cps'

X_name = 'ScanX_set'
Y_name ='ScanY_set'
out_chem = '15000' # energy not part of chemical imaging


#ATTENUATION (values): multiply by tx, divide by attenuation, this is when not using 15 kev map. must be in same order as els_to_use variable
atten_on = 0 # 1 if you want to correct attenuation, 0 if only raw values
num_scal = 0.005 # if no attenuation, enter the value you want to scale the numerator if there is an external calibration for example
els_to_use = ['sort_Tl-La','sort_Mn-Ka','sort_As-Ka']


#OTHER TOOLS
variant_comparison = 0 # in order to compare different datasets, the masks need to be identical to the first map


''' 
code
'''
dset_names = [X_name, Y_name,alg_el,El1_name,El2_name,El3_name]
gridtest = [X_name,Y_name]

## reading part
print('###########')
print("LET'S GO!!!")
print('###########')
    
refs_red_ls = glob.glob(os.path.join(refs_red,'*.nor'))
refs_ox_ls = glob.glob(os.path.join(refs_ox,'*.nor'))
redox = ['red','ox']
ref_list = refs_red_ls+refs_ox_ls
red_ls = range(0,len(refs_red_ls))
ox_ls = range(len(refs_red_ls),len(ref_list))
couples = [(red,ox) for red in red_ls for ox in ox_ls]
len_red = len(refs_red_ls)


#read hdf5

# read groups, make list
# read elements (group + / + names of elements)


alldirs = [x[0] for x in os.walk(path) if 'extracted' in x[0]]
filelist = [y for ls in [glob.glob(os.path.join(sub,'*.h5')) for sub in alldirs] for y in ls]

#samples = glob.glob(os.path.join(path,'*.h5'))

if not run_all:
    samples = [sample for sample in filelist if os.path.basename(sample) in run]
else:
    samples = [sample for sample in filelist if any(a in sample for a in ignore)]


#%%
samp_count = 0
for sample in samples:
#%%
    dir_out_r = os.path.join(os.path.dirname(sample),'LCF_out')
    dir_out_root = ['masks','LCF']

    samp_name = os.path.basename(sample)
    print('#*#*#*#*#*#*#*#*#*#*#*#*#')
    print('running sample {}'.format(samp_name))  
    with h5py.File(sample,'r') as f:   
        energies = list(f.keys())# different groups of the data, as string
        dset={}
        for energy in energies:
            dset[energy] = {}
            name = f.get(energy)
            for x in name:
                if x in dset_names:
                    dset[energy][x] = name.get(x)[:]
    # this is to check if the dataset is actually a chemical redox dataset,
    # and usually if there is less than 3 energies it is not
    if len(energies) < 3:
        continue
                    
    LCF_energies = [energy for energy in energies if out_chem not in energy]
    en_values = [float(energy) for energy in LCF_energies]
    
    array, allign = {}, {}
    array = {key:{} for key in energies} # this needs to be the 4D shape of the data. so energies x rois x mapsize
    allign = {key:{} for key in energies}
    '''
    this part below is to figure out if and where there is a different sized map in the set.
    the idea is to upsize the small maps to the big one to not loose info of the big ones
    '''
    #load the scanX_set and scanY_set values of the hdf5 images for each energy
    grid = [[dset[name][val] for val in dset[name].keys() if val in gridtest] for name in dset]
    grid_shape = [grid[energy][0].shape for energy in range(len(grid))]
    grid_dict = {energy+'eV':grid_shape[en] for en,energy in enumerate(energies)}
    gridindex = dict((i, grid_shape.count(i)) for i in grid_shape)
    
    if len(gridindex) > 1:
        print("there is one map that has a different size. I'll interpolate it to the other maps' size (increase)")
        print('')
        grid_min_ind = grid_shape.index(min(gridindex))
        grid_max_ind = grid_shape.index(max(gridindex))
        tmp = pd.DataFrame(data=grid_dict,index=['X','Y']).transpose()
        tmp.to_csv(os.path.join(sample,'diagnostic_interpolation.txt'),sep='\t')
    else:
        grid_min_ind, grid_max_ind = -1,-1
    '''            
    #this part below loops over the different energies
    # transform it because we don't have to read an image anymore but read as numpy 
    # arrays the data in the hdf5 file
    '''
    alg_el_sel = []
    count = 0 # this is to initialize the overall_mismatch variable
    for nen,energy in enumerate(energies): # this will iterate over all energies within a sample.
        tmp = dset[energy]# list of all the rois within a group, or dictionnary
        if moving_avg:
            sfx = 'mv_avg_{}x{}'.format(str(mov_bin),str(mov_bin))
            # below, filename is not necessary if we have a dictionary with the names of the rois, but keeping for lazyness
            filenames = [y+sfx for y in tmp.keys()]
        else:
            filenames = [y for y in tmp.keys()]
        alg_el_sel.append([filename for filename in filenames if alg_el in filename][0])
        if grid:
            if nen == grid_min_ind:
                X,Y = (grid[grid_max_ind][0],grid[grid_max_ind][1])
                for y,x in enumerate(tmp):
                    array[energy][filenames[y]] = cv2.resize(tmp[x],(len(X),len(Y)))
                allign[energy] = {alg_el_sel[nen]:array[energy][alg_el_sel[nen]]}
            else:
                array[energy] = {filenames[y]:tmp[x] for y,x in enumerate(tmp)}
                allign[energy] = {alg_el_sel[nen]:array[energy][alg_el_sel[nen]]}
        else:
            array[energy] = {filenames[y]:tmp[x] for y,x in enumerate(tmp)}
            allign[energy] = {alg_el_sel[nen]:array[energy][alg_el_sel[nen]]}
        if count == 0:
            overall_mismatch = np.empty(allign[energies[0]][alg_el_sel[0]].shape)
        '''
        allignment part
        the idea behind this routine is to allign the images to account for energy-dependent drift
        by looking at features in a fluorescence map that do not change as a function of incident
        energy. it requires the files to all have the same shape. it only fixes translation in X and Y. 
        there should actually only be changes in the Y direction, but there is 
        also probably changes in the beam spot profile which we make the assumption are negligeable (sub-pixel)
        '''
        shift, error, diffphase = phase_cross_correlation(allign[energies[0]][alg_el_sel[0]], allign[energy][alg_el_sel[nen]],upsample_factor=100)
        diagnostic = sp.ndimage.shift(allign[energy][alg_el_sel[nen]],shift) - allign[energies[0]][alg_el_sel[0]]
        try:
            overall_mismatch = overall_mismatch + np.abs(diagnostic)
        except:
            if allign[energies[nen]][alg_el_sel[0]].shape != allign[energies[0]][alg_el_sel[0]].shape:
                print('the images are not the same size')
                print('')
        for key in array[energy]:
            # this algorithm below makes the shift based on the calculated translation.
            array[energy][key] = sp.ndimage.shift(array[energy][key],shift)
            if moving_avg:
                array[energy][key] = mul.mov_avg(array[energy][key],movavg_shape,mov_bin)
                dirname =  os.path.join(dir_out_r,'out_movavg_{}x{}'.format(str(mov_bin),str(mov_bin)))
            else:
                dirname = os.path.join(dir_out_r,'out')
            out_all = os.path.join(dir_out_r,dirname,'allign',os.path.basename(energy))
            mul.safe_mkdir(out_all)
            img1 = Image.fromarray(array[energy][key])
            img_name = os.path.join(out_all,key+'_alligned.tif') # check if it actually works here
            img1.save(img_name)
        count += 1
    dir_out = [os.path.join(dirname,direc) for direc in dir_out_root]
    for direc in dir_out:
        mul.safe_mkdir(direc)
    diag = Image.fromarray(overall_mismatch)
    diag_name = os.path.join(os.path.dirname(out_all),'%s_allign_diag.tif' % alg_el)
    diag.save(diag_name)
    shape = np.shape(overall_mismatch)
# reference reading
    print('\t######################')
    print('\t# reading references #')
    print('\t######################')

    ref_head = [os.path.basename(ref)[0:10] for ref in ref_list]
    N_ref = len(ref_list)
    nor_vals = np.zeros((len(LCF_energies),len(ref_list)))
    energy_refs = [float(os.path.basename(energy)) for energy in LCF_energies]
    for index,reference in enumerate(ref_list):
        ref = np.loadtxt(reference)
        for en,energy in enumerate(energy_refs):
            value = ref[np.where(np.around(ref[:,0],decimals=0)==energy),1]
            nearest = ref[np.abs(ref[:,0]-energy).argmin(),1]
            if value.size == 1:
                nor_vals[en,index] = value.item()
            elif value.size == 0:
                nor_vals[en,index] = nearest
            else:
                nor_vals[en,index] = np.mean(value)
    nor_vals = nor_vals/nor_vals[-1] # this is make the refs similar to the data (last energy is 1 in the data)--> "normalizing" the references also in case they were not already
    
    '''
    normalization part -- CAN STILL BE IMPROVED MAYBE?
    this part is to attempt to make a normalization of the maps. it will take the average for
    the highest energy map, and the minimum for the lowest energy map to normalize the data.
    this may be not the best solution, but I did not find something better for the moment
    '''
    # here below divide by the attenuation of El1 by the filter
    hi_El = array[LCF_energies[-1]][[k for k in array[LCF_energies[-1]] if El1_name in k][0]]
    lo_El = array[LCF_energies[0]][[k for k in array[LCF_energies[0]] if El1_name in k][0]]
    El3_map = array[LCF_energies[-1]][[k for k in array[LCF_energies[-1]] if El3_name in k][0]] # takes highest energy map
    El1_map = array[LCF_energies[-1]][[k for k in array[LCF_energies[-1]] if El1_name in k][0]]
    El2_map = array[LCF_energies[-1]][[k for k in array[LCF_energies[-1]] if El2_name in k][0]]
    
    correct_vals = [El3_map,El1_map,El2_map]
    names = ['El3_atten','El1_atten','El2_atten']
    dir_atten = mul.safe_mkdir(os.path.join(dirname,'attenuation_corrected'),1)
    for ind_att,mp in enumerate(correct_vals):
        Image.fromarray(mp).save(os.path.join(dir_atten,names[ind_att]+'.tif'))
    if El1_masking:
        El1_mask = np.copy(El1_map)
        El1_mask[El1_mask<=El1_threshold] = 0
        El1_mask[El1_mask>El1_threshold] = 1
    else:
        El1_mask = np.ones(np.shape(El1_map))
    
    sel_en = LCF_energies[-1]
            
    El_sel = [k for k in array[sel_en] if El1_name in k][0]
    Den_sel = [k for k in array[sel_en] if El2_name in k][0]
    Den_raw = np.ma.masked_less(array[sel_en][Den_sel]*El1_mask,1)
    El_raw = np.ma.masked_less(array[sel_en][El_sel]*El1_mask,1)
    hi_El_msk = np.ma.masked_array(hi_El,Den_raw.mask)
    lo_El_msk = np.ma.masked_array(lo_El,Den_raw.mask)
    El1_int_scal = np.ma.fix_invalid(hi_El/np.nanmax(hi_El),fill_value=0)
    El2_int_scal = np.ma.fix_invalid(Den_raw/np.nanmax(Den_raw),fill_value=0)

### all changes for hdf5 reading are up to here, below everything should be fine###
# mask for all data
    '''
    here is a mask to select only the pixels with minimum counts higher than background for El1
    it takes the mean value of the highest energy map and uses this as a threshold for creating a num_mask
    '''
    if mask:
        if opt:
            mask_Num = np.greater_equal(hi_El,lo_El*edge_ratio)
        else:
            mask_Num = np.greater_equal(hi_El,np.mean(lo_El))
        Image.fromarray(mask_Num.astype(int)).save(os.path.join(dir_out[1],'num_mask.tif'))
    else:
        mask_Num = np.ones(np.shape(hi_El))

# population of the arrays with normalized data, fixed for attenuation of filter
    el_norm = np.zeros((len(LCF_energies),shape[0],shape[1]))
    for Eind, energy in enumerate(LCF_energies):
        sel_El = [k for k in array[energy] if El1_name in k][0]
        data = (((array[energy][sel_El]*El1_mask)-lo_El)/(hi_El-lo_El))*El1_mask # used to be att
        el_norm[Eind,:,:] = np.ma.fix_invalid(data,fill_value=0)

    ''' 
    LCF selection/rating based on residuals after testing all references on each pixel
    1. evaluate the residuals for all references for each pixel
    2. for each pixel, select only the value with lowest residual and assign it in the map
    3. save a list with the reference and the index
    4. evaluate the 2 component fit that works the best, with the lowest residual
    5. select in a final map whether the 1 component is better or the 2 component
    '''

# ROI selection
    if ROI_opt:
        ROI, roi_masks, roi_coord = mul.ROIs(sel_roi,el_norm, hi_El, Den_raw, dirname,image_scl)
        outfilename = 'roi.csv'
    else:
        ROI, roi_masks = {},{}
        ROI['fullmap'] = el_norm
        roi_masks['fullmap'] = [0,np.shape(el_norm)[1], 0, np.shape(el_norm)[2]]
        outfilename = 'full.csv'

    
        print('\n\t# saving LCF images #')
        print('\t#################')

#%%    
    valid_roi = [roi for roi in ROI if ROI[roi].size] #  this is because the quit does not always work
    LCF_dict= {}
    LCF_avg = {}
    allpix = {}
    spectrum = {}
    
    for roi_ind,roi in enumerate(valid_roi):      
        print('\t')
        print('\t# running roi {} of {} #'.format(roi_ind,len(valid_roi)+1))
        print('\t#################')
        dir_out = [os.path.join(dirname,roi,xpath) for xpath in dir_out_root]  
        [mul.safe_mkdir(dir_tmp) for dir_tmp in dir_out]
        x1,x2,y1,y2 = roi_masks[roi]
        
        hi_el_roi = hi_El[x1:x2,y1:y2]
        Den_raw_roi = Den_raw[x1:x2,y1:y2]
        El_raw_roi = El_raw[x1:x2,y1:y2]
        mask_Num_roi = mask_Num[x1:x2,y1:y2]
        El1_mask_roi = El1_mask[x1:x2,y1:y2]
        El3_roi = El3_map[x1:x2,y1:y2]
        El1_roi = El1_map[x1:x2,y1:y2]
        El2_roi = El2_map[x1:x2,y1:y2]
        El1_int_scal_roi = El1_int_scal[x1:x2,y1:y2]
        El2_int_scal_roi = El2_int_scal[x1:x2,y1:y2]
        # this part saves all the pixel results as images
        shape_roi = (x2-x1,y2-y1)    
        G = np.zeros((shape_roi[0],shape_roi[1]))
        allpix[roi] = pd.DataFrame({'{}_roi'.format(El1_name):np.ma.masked_less_equal(El1_roi*El1_mask_roi,0).flatten(),
                  '{}_roi'.format(El2_name):np.ma.masked_less_equal(El2_roi*El1_mask_roi,0).flatten(), 
                  '{}/{}_roi'.format(El1_name,El2_name):np.ma.masked_less_equal(El1_roi*El1_mask_roi,0).flatten()/np.ma.masked_less_equal(El2_roi*El1_mask_roi,1).flatten(),
                  '{}_roi'.format(El3_name):np.ma.masked_less_equal(El3_roi*El1_mask_roi,0).flatten()})
        roi_el_norm = el_norm[:,x1:x2, y1:y2]
        roi_spectrum = np.mean(roi_el_norm.reshape(len(LCF_energies), -1), 1)
        spectrum[roi] = pd.Series(roi_spectrum, index=en_values)
        

        if roi_lcf:
            print('\n\t# running pixel LCF on ROI %s #' %roi)
            print('\t#################')
                  

            shape_roi = (x2-x1,y2-y1) # this could be 1 less than what it should be
            if sum(shape_roi) <= 2:
                continue
            LCF_sel_header = ['2comp_red','2comp_ox','1comp']

            print('\n\t# saving ROI %s images #' %roi)
            print('\t#################')
            
            LCF_1comp, LCF_1comp_res, LCF_1comp_val = mul.pixelLCF(shape_roi,ROI[roi],nor_vals,ref_list)
            LCF_2comp, LCF_2comp_res, LCF_2comp_val = mul.pixel_2compLCF(shape_roi,ROI[roi],nor_vals,couples)
            LCF_select, LCF_sel_oxstate = mul.LCF_sel(shape_roi,len_red,LCF_2comp, LCF_2comp_val,LCF_2comp_res,LCF_1comp, LCF_1comp_res)
            
            RGB = mul.RGB_fun(LCF_sel_oxstate[0],G,LCF_sel_oxstate[1])
            cv2.imwrite(os.path.join(dir_out[1], roi+'_redR_nanG_oxB_nssr_sel.tif'),RGB)
            
            RGB = mul.RGB_fun(LCF_2comp_val[0],G,LCF_2comp_val[1])
            cv2.imwrite(os.path.join(dir_out[1], roi+'_redR_nanG_oxB_abs.tif'),RGB)
            
            RGB_scEl1 = mul.RGB_fun(LCF_sel_oxstate[0]*El1_int_scal_roi,G,LCF_sel_oxstate[1]*El1_int_scal_roi)
            cv2.imwrite(os.path.join(dir_out[1], roi+'_redR_nanG_oxB_{}.tif'.format(El1_name)),RGB_scEl1)
        
            RGB_scEl2 = mul.RGB_fun(LCF_sel_oxstate[0]*El2_int_scal_roi,G,LCF_sel_oxstate[1]*El2_int_scal_roi)
            cv2.imwrite(os.path.join(dir_out[1], roi+'_redR_nanG_oxB_{}.tif'.format(El2_name)),RGB_scEl2)
            
            Image.fromarray(LCF_1comp).save(os.path.join(dir_out[1], roi+'1comp_rating.tif' ))
            Image.fromarray(LCF_1comp_res).save(os.path.join(dir_out[1], roi+'1comp_NSSR.tif' ))
            
            for couple in range(2):
                Image.fromarray(LCF_2comp[couple]).save(os.path.join(dir_out[1], roi+'_%s_rating.tif' % redox[couple]))
            Image.fromarray(LCF_2comp_res).save(os.path.join(dir_out[1], roi+'_NSSR.tif'))
            for num,comp in enumerate(LCF_2comp_val):
                Image.fromarray(LCF_2comp_val[num]).save(os.path.join(dir_out[1], roi+'_2comp_%s_val.tif' % redox[num]))
                Image.fromarray(LCF_sel_oxstate[num]).save(os.path.join(dir_out[1], roi+'_2comp_norm%s_val.tif' % redox[num]))

            for ind, index in enumerate(LCF_select):
                Image.fromarray(index).save(os.path.join(dir_out[1], roi+'LCF_sel_%s_rating.tif' % LCF_sel_header[ind]))
            refs_corr = ['no LCF']+ref_head
            refs = pd.DataFrame([[refs_corr[b] for b in a] for a in LCF_2comp.reshape(2,-1).T.astype(int)],
                                columns=['LCF_ref_ox','LCF_ref_red'])
            allpix[roi]['{}_Ox'.format(El1_name)]=np.ma.masked_invalid(LCF_sel_oxstate[1]).flatten()
            allpix[roi] = allpix[roi].join(refs)

            # make the correlations of El1 and El2 with oxidation state
            cleaned = allpix[roi].dropna()
            plt.rcParams.update({'font.size':18})
            points = plt.scatter(cleaned['{}_roi'.format(El2_name)],cleaned['{}_roi'.format(El1_name)],
                                 c=cleaned['{}_Ox'.format(El1_name)],vmin = 0, vmax = 1,s=10,cmap='Spectral_r')
            m,b = np.polyfit(cleaned['{}_roi'.format(El2_name)],cleaned['{}_roi'.format(El1_name)],1)
            cbar = plt.colorbar(points)
            cbar.set_label('{}(Ox) percent'.format(El1_name))
            plt.xlim(cleaned['{}_roi'.format(El2_name)].min()-10,cleaned['{}_roi'.format(El2_name)].max()+10)
            plt.ylim(cleaned['{}_roi'.format(El1_name)].min()-10,cleaned['{}_roi'.format(El1_name)].max()+10)
            sb_plt = sns.regplot('{}_roi'.format(El2_name),'{}_roi'.format(El1_name),data=cleaned,scatter = False,color='.1',
                                 line_kws={'color':'red','linestyle':'dashed'})
            sb_plt.set(ylabel='{} raw counts'.format(El1_name),xlabel='{} raw counts'.format(El2_name))
            plt.text(cleaned['{}_roi'.format(El2_name)].min()-10,cleaned['{}_roi'.format(El1_name)].max(),
                     'regr. vals\n{}/{} = {}\n{} background = {}'.format(El1_name,El2_name,round(m,3),El1_name,round(b,3)),alpha=.75)
            plt.savefig(os.path.join(dir_out[1],'{}_{}_{}_correlations.svg'.format(roi,El1_name,El2_name)))
            plt.close()
            
            
        third_el = [k for k in array[sel_en] if El3_name in k][0]
        third_el2 = array[sel_en][third_el]
        
        RGB_El2 = mul.RGB_fun(Den_raw_roi,G,hi_el_roi)
        cv2.imwrite(os.path.join(dir_out[1], roi+'_{}R_nanG_{}B_scaleint.tif'.format(El2_name, El1_name)),RGB_El2)
        
        RGB_El1Int = mul.RGB_fun(Den_raw_roi*El1_int_scal_roi,G,hi_el_roi*El1_int_scal_roi)
        cv2.imwrite(os.path.join(dir_out[1], roi+'_{}R_nanG_{}B_scale{}.tif'.format(El2_name, El1_name, El1_name)),RGB_El1Int)
        
        RGB_El2Int = mul.RGB_fun(Den_raw_roi*El2_int_scal_roi,G,hi_el_roi*El2_int_scal_roi)
        cv2.imwrite(os.path.join(dir_out[1], roi+'_{}R_nanG_{}B_scale{}.tif'.format(El2_name, El1_name,El1_name)),RGB_El2Int)
#%%        
# save all the text files with elaborated results
    tmp = pd.DataFrame(data={str(index+1):ref for index,ref in enumerate(ref_head)},index = ['reference'])
    tmp = tmp.transpose()

# this is raw if wanting to look at the pseudo xanes
    roi_option = ['fullmap','rois']
    im_lcf = ['no_im_lcf','im_lcf']
    with pd.ExcelWriter(os.path.join(dirname,dir_out_root[1],'output_{}_{}.xlsx'.format(roi_option[ROI_opt],im_lcf[roi_lcf]))) as writer:
        tmp.to_excel(writer,sheet_name='ref_list')
        for roi in valid_roi:
            allpix[roi].to_excel(writer,sheet_name='{}_allpixels'.format(roi))
            spectrum[roi].to_excel(writer,sheet_name='{}_avg_spectrum'.format(roi))
    samp_count +=1
